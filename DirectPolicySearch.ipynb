{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) #Make full screen width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !yes | pip uninstall protobuf\n",
    "# !yes | pip uninstall tensorflow\n",
    "# !yes | pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --force-reinstall tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export CUDA_VISIBLE_DEVICES=0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.4.0\n",
      "  Using cached tensorflow-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7 MB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Using cached grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "Collecting h5py~=2.10.0\n",
      "  Using cached h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Using cached numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting six~=1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting tensorboard~=2.4\n",
      "  Using cached tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Collecting importlib-metadata\n",
      "  Using cached importlib_metadata-3.4.0-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.7-py3-none-any.whl (34 kB)\n",
      "Collecting setuptools>=41.0.0\n",
      "  Using cached setuptools-51.1.2-py3-none-any.whl (784 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Using cached tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "Installing collected packages: urllib3, pyasn1, idna, chardet, certifi, zipp, typing-extensions, six, setuptools, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, wheel, werkzeug, tensorboard-plugin-wit, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 4.0.1 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "spyder 4.0.1 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "tensorflow-serving-api 1.15.0 requires tensorflow~=1.15.0, but you have tensorflow 2.4.0 which is incompatible.\n",
      "awscli 1.18.197 requires rsa<=4.5.0,>=3.1.2; python_version != \"3.4\", but you have rsa 4.7 which is incompatible.\n",
      "tensorflow-gpu 1.15.4 requires gast==0.2.2, but you have gast 0.3.3 which is incompatible.\n",
      "tensorflow-gpu 1.15.4 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.19.5 which is incompatible.\n",
      "tensorflow-gpu 1.15.4 requires tensorboard<1.16.0,>=1.15.0, but you have tensorboard 2.4.0 which is incompatible.\n",
      "tensorflow-gpu 1.15.4 requires tensorflow-estimator==1.15.1, but you have tensorflow-estimator 2.4.0 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.0 certifi-2020.12.5 chardet-4.0.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.24.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 idna-2.10 importlib-metadata-3.4.0 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.19.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7 setuptools-51.1.2 six-1.15.0 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.2 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1 zipp-3.4.0\n",
      "\u001b[33mWARNING: You are using pip version 20.3; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !yes | pip uninstall tensorflow\n",
    "!pip install --ignore-installed --upgrade tensorflow==2.4.0\n",
    "\n",
    "# !pip install --ignore-installed --upgrade tensorflow-gpu==2.4.0\n",
    "\n",
    "# _ = !pip install wandb\n",
    "# # _ = !pip install dirsync\n",
    "# import wandb\n",
    "# wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; import re; import sys; import importlib\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import pandas as pd; import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LeakyReLU, Concatenate\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import tqdm\n",
    "\n",
    "pd.set_option(\"display.precision\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (FunctionsTF.py, line 132)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/home/ec2-user/SageMaker/PythonFiles/FunctionsTF.py\"\u001b[0;36m, line \u001b[0;32m132\u001b[0m\n\u001b[0;31m    tf.print('file path: {}'.format(file_path))\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#This is to import local modules\n",
    "sys.path.append('/home/ec2-user/SageMaker/PythonFiles')\n",
    "import FunctionsTF as F\n",
    "importlib.reload(F) #In case need to reload module after change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://hilcorp-l48operations-plunger-lift-main/RecommendedSettings/2021-01-11-RecommendedSettings.csv\n"
     ]
    }
   ],
   "source": [
    "homeDirectory = '/home/ec2-user/SageMaker/'\n",
    "\n",
    "model_name = r'20201216_460k_Param_LSTM_Skip_resBlock_311Epoch.h5'\n",
    "model_save_location = homeDirectory + r'Models/' + model_name\n",
    "\n",
    "bucket_name = 'hilcorp-l48operations-plunger-lift-main'\n",
    "\n",
    "# outputPath = homeDirectory + r'RecommendedSettings/' + datetime.today().strftime('%Y-%m-%d') + '-RecommendedSettings.csv'\n",
    "outputPath = 's3://hilcorp-l48operations-plunger-lift-main/RecommendedSettings/' + datetime.today().strftime('%Y-%m-%d') + '-RecommendedSettings.csv'\n",
    "print(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# device_lib.list_local_devices()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name=u'/physical_device:GPU:0', device_type=u'GPU')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c545b2eec3e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"],\n\u001b[0;32m----> 2\u001b[0;31m                       cross_device_ops=tf.contrib.distribute.AllReduceCrossDeviceOps(\n\u001b[0m\u001b[1;32m      3\u001b[0m                          all_reduce_alg=\"hierarchical_copy\")\n\u001b[1;32m      4\u001b[0m                                                    )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "# mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"],\n",
    "#                       cross_device_ops=tf.contrib.distribute.AllReduceCrossDeviceOps(\n",
    "#                          all_reduce_alg=\"hierarchical_copy\")\n",
    "#                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_save_location, compile = False, custom_objects = {'LeakyReLU' : LeakyReLU()})\n",
    "model.summary()# tf.keras.utils.plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the column names\n",
    "obj = s3_client.get_object(Bucket = bucket_name, Key= 'DataByAPI/0506705008.csv') \n",
    "df = pd.read_csv(obj['Body'], index_col = None, header = 0, dtype = str,nrows = 0)#This loads the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find index of certain columns\n",
    "xCols = df.columns[4:].to_list()\n",
    "ExcessOffTimeIndex = xCols.index('FALL_EST_DIFF_MINS')\n",
    "ShutInTimeIndex = xCols.index('SHUTIN_LENGTH')\n",
    "ventIndex = xCols.index('WELL_VENT_SEC')\n",
    "TimeIndex = xCols.index('FDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 64\n",
    "batch_size = 2\n",
    "\n",
    "lTFRecordFiles = !ls /home/ec2-user/SageMaker/TFRecordFiles\n",
    "lTFRecordFiles =  [homeDirectory + r'TFRecordFiles/' + fName for fName in lTFRecordFiles]\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset(lTFRecordFiles)\n",
    "allWellDs = raw_dataset.map(F.parse_raw_examples_UWI)\n",
    "\n",
    "# allWellDs = allWellDs.map(lambda x, y, UWI: (x[:100,:],y[:100,:],UWI))#This is just for testing purposes to trim X for shorter computation\n",
    "\n",
    "allWellDs = allWellDs.prefetch(buffer_size)\n",
    "allWellDs = allWellDs.map(lambda x, y, UWI: (tf.reverse(x, axis = [0]),tf.reverse(y, axis = [0]),UWI))\n",
    "allWellDs = allWellDs.padded_batch(batch_size, padded_shapes=([None,79],[None,2],[]))\n",
    "allWellDs = allWellDs.map(lambda x, y, UWI: (tf.reverse(x, axis = [1]),tf.reverse(y, axis = [1]),UWI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm.tqdm_notebook(allWellDs.take(5)): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(prediction, y):\n",
    "    rateLoss = -1*prediction[:,-1,0]\n",
    "\n",
    "    acceptablePlungerSpeeds = y[:,-22:-2,1].mean(axis = 1)*1.01 #Avg of last 20 arrival speeds * factor. The factor increases safety but decreases production increase.\n",
    "    acceptablePlungerSpeeds = np.clip(acceptablePlungerSpeeds,650,800)#No acceptable plunger speed below 650 or above 800 is allowed. These values are cliped to that range\n",
    "\n",
    "    plungerSpeed = prediction[:,-1,1]\n",
    "    bUnacceptablePlungerSpeed = (K.cast(K.less(plungerSpeed,acceptablePlungerSpeeds),'float32'))\n",
    "    plungerLoss = tf.square(plungerSpeed-acceptablePlungerSpeeds)*bUnacceptablePlungerSpeed\n",
    "\n",
    "    return plungerLoss+rateLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 11 21:06:52 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   32C    P0    22W / 300W |      2MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSuggestions = pd.DataFrame()\n",
    "for j, (tX, ty, UWI) in tqdm.tqdm_notebook(enumerate(allWellDs.take(5))):\n",
    "    # break\n",
    "    # if j >10: break\n",
    "    X = tX.numpy()\n",
    "    y = ty.numpy()\n",
    "    UWIs = list(map(lambda x: x.decode('utf-8'),UWI.numpy()))\n",
    "\n",
    "    if X.shape[0] == 0 or len(UWIs)!=X.shape[0]: continue\n",
    "\n",
    "    # print(UWIs)\n",
    "    print('X shape: {}'.format(X.shape))\n",
    "    #This is used to monitor gradient ascent and log changes in loss\n",
    "    wellIndex = 0 #This well is plotted during gradient ascent\n",
    "    print('################### Focus API: {}, AVG 20 Plunger Arrival Speed: {:.1f} ####################'.format(UWIs[wellIndex],y[wellIndex,-22:-2,1].mean()))\n",
    "\n",
    "    # X = X.astype('float32')#This line may not be necessary\n",
    "    XConstantTensor = tf.constant(X[:,:-1,:])#All of X except the last cycle\n",
    "    TrainableX = tf.Variable(X[:,-1:,:], trainable = True) #This is just the last cycle of X\n",
    "\n",
    "    #This will be used to only change the controllable columns\n",
    "    bMask = np.zeros([X.shape[0],1,X.shape[2]], dtype = np.float32)#Shape is (# wells, 1, # features)\n",
    "    bMask[:,:,-2:] = 1\n",
    "    bMaskTensor = tf.constant(bMask)\n",
    "\n",
    "    #Finish making the X tensor\n",
    "    XTensor = Concatenate(axis = 1)([XConstantTensor,TrainableX])\n",
    "    #Save the origional predictions for the next cycle\n",
    "    yhatOriginal = model(XTensor)[:,-1:,:]\n",
    "\n",
    "    lr = 1e2\n",
    "    lossHistory = []\n",
    "    for i in range(5):#This many gradient loops, increase the # to increase the difference between current and suggested settings\n",
    "        with tf.GradientTape() as tape:\n",
    "            XTensor = Concatenate(axis = 1)([XConstantTensor,TrainableX])\n",
    "            yhat = model(XTensor)\n",
    "            current_loss = loss_function(yhat,y)  \n",
    "\n",
    "        #Here is the dLoss/dX calculation\n",
    "        dX = tape.gradient(current_loss, [TrainableX])[0]\n",
    "\n",
    "        #Combining the dL/dX and regularization terms\n",
    "        dX_reg = dX#+regGrad\n",
    "\n",
    "        # Here I'm clipping the gradient to max of 1 unit change per iteration\n",
    "        dX_reg = tf.clip_by_value(dX_reg,-1./lr,1./lr)\n",
    "\n",
    "        #This prevents the actor form changing settigns that controllers don't have.\n",
    "        dX_masked = tf.math.multiply(dX_reg,bMaskTensor)\n",
    "\n",
    "        #Here the gradients are applied\n",
    "        TrainableX = tf.math.subtract(TrainableX,dX_masked*lr)\n",
    "\n",
    "        #Not sure if need this line\n",
    "        TrainableX = tf.Variable(TrainableX, trainable = True)\n",
    "\n",
    "        #This is to plot the result of the settings updates\n",
    "        productionRate = yhat[wellIndex,-1,0]\n",
    "        plungerSpeed = yhat[wellIndex,-1,1]\n",
    "\n",
    "        lossHistory.append(tf.reduce_sum(current_loss))\n",
    "\n",
    "        if i%2 == 0: \n",
    "            print('{:,.2f} Loss Sum,  \\t {:,.2f} DMCFD,\\t  API:{} Outcome Loss: {:,.2f},    \\t DMCFD: {:,.2f},\\t Plunger Speed: {:,.2f},\\t Csg-Line:{:,.2f},\\t CRPct:{:,.2f}'.format(\n",
    "                tf.reduce_sum(current_loss),\n",
    "                tf.reduce_sum(yhat[:,-1,0])-tf.reduce_sum(yhatOriginal[:,-1,0]),\n",
    "                UWIs[wellIndex],\n",
    "                current_loss[wellIndex],\n",
    "                yhat[wellIndex,-1,0]-yhatOriginal[wellIndex,-1,0],\n",
    "                plungerSpeed,\n",
    "                XTensor.numpy()[wellIndex,-1,-1],#Suggested Csg-Line\n",
    "                XTensor.numpy()[wellIndex,-1,-2]#Suggested CR Pct End Flow\n",
    "                ))\n",
    "\n",
    "    #Now I save the recomended settings\n",
    "    df = pd.DataFrame(XTensor.numpy()[:,-1,-2:],columns = ['SuggestedCRPctEndFlow','SuggestedCsgMinusLine'])\n",
    "    df.insert(1,'LastCRPctEndFlow',X[:,-1,-2])\n",
    "    df.insert(2,'DiffCRPctEndFlow',XTensor.numpy()[:,-1,-2] - X[:,-1,-2])\n",
    "    df.insert(4,'LastCsgMinusLine',X[:,-1,-1])\n",
    "    df.insert(5,'DiffCsgMinusLine',XTensor.numpy()[:,-1,-1] - X[:,-1,-1])\n",
    "\n",
    "    df.insert(6,'AvgExcessOffTime',X[:,-200:-2,ExcessOffTimeIndex].mean(axis = 1)) #If this is 0 then look at changing the plunger drop time to allow the controller to use the suggested Otrig value.\n",
    "    df.insert(7,'SITimeSTD',X[:,-200:-2,ShutInTimeIndex].std(axis = 1))#If this changes a timer is not controlling the off time\n",
    "    df.insert(8,'AvgVentSeconds',X[:,-200:-2,ventIndex].mean(axis = 1))#average vent time over last 200 cycles\n",
    "    df.insert(9,'dLoss/dT',dX[:,0,TimeIndex])#This shows if the model thinks rate goes up or down over time (if the plunger speed is high enough)\n",
    "    df.insert(10,'LastCycleTime',X[:,-1,TimeIndex])#This is the days between 1/1/1900 and the last cycle\n",
    "    df.insert(11,'Policy Loss',current_loss)\n",
    "\n",
    "    df.insert(0,'UWI',UWIs)\n",
    "    df.insert(1,'DMCFD',yhat[:,-1,0]-yhatOriginal[:,-1,0])\n",
    "    df.insert(2,'Avg20DMCFD',yhat[:,-1,0]-y[:,-22:-2,0].mean(axis = 1))\n",
    "    df.insert(3,'PredPSSuggested',yhat[:,-1,1])\n",
    "    df.insert(4,'PredPSOriginal',yhatOriginal[:,-1,1])\n",
    "    df.insert(5,'Avg20LastPS',y[:,-22:-2,1].mean(axis = 1))\n",
    "\n",
    "\n",
    "    dfSuggestions = pd.concat((dfSuggestions,df))\n",
    "    # break\n",
    "    # if j > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSuggestions.sort_values(by = ['DMCFD'], ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((axMCF,axPS),(ax1, ax2)) = plt.subplots(2, 2, figsize=(25,10))\n",
    "\n",
    "axMCF.hist(dfSuggestions['DMCFD'],bins=100, alpha=0.5, label = 'Change in Gas Rate')\n",
    "axMCF.set_yscale('log')\n",
    "axMCF.set_title('Predicted change in gas rate: {:,.2f} MCFD'.format(dfSuggestions['DMCFD'].sum()))\n",
    "axMCF.legend()\n",
    "axMCF.grid(axis = 'y')\n",
    "axMCF.set_xlabel('Change in Gas Rate');axMCF.set_ylabel('Well Count');\n",
    "\n",
    "axPS.hist(dfSuggestions['PredPSSuggested'],bins=100, alpha=0.5, label = 'Suggested Policy Predicted Result')\n",
    "axPS.hist(dfSuggestions['PredPSOriginal'],bins=100, alpha=0.5, label = 'Current Value')\n",
    "axPS.set_yscale('log')\n",
    "axPS.set_title('Plunger Speed Histogram')\n",
    "axPS.legend()\n",
    "axPS.grid(axis = 'y')\n",
    "axPS.set(xlim=(0, 1500))#, ylim=(-4.5e3, -2e3))\n",
    "axPS.set_xlabel('Plunger Speed');axPS.set_ylabel('Well Count');\n",
    "\n",
    "ax1.hist(dfSuggestions['SuggestedCsgMinusLine'].clip(0,200),bins=100, alpha=0.5, label = 'Suggested Value')\n",
    "ax1.hist(dfSuggestions['LastCsgMinusLine'].clip(0,200),bins=100, alpha=0.5, label = 'Current Value')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title('CSG-Line Histogram')\n",
    "ax1.legend()\n",
    "ax1.grid(axis = 'y')\n",
    "# ax1.set(xlim=(0, 200))\n",
    "ax1.set_xlabel('Casing - Line Pressure Open Trigger');ax1.set_ylabel('Well Count');\n",
    "\n",
    "ax2.hist(dfSuggestions['SuggestedCRPctEndFlow'],bins=100, alpha=0.5, label = 'Suggested Value')\n",
    "ax2.hist(dfSuggestions['LastCRPctEndFlow'],bins=100, alpha=0.5, label = 'Current Value')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title('Crit Flow Pct End Flow Histogram')\n",
    "ax2.legend()\n",
    "ax2.grid(axis = 'y')\n",
    "# ax.set(xlim=(0, 200))#, ylim=(-4.5e3, -2e3))\n",
    "ax2.set_xlabel('Critical Flow Percent Close Trigger');ax2.set_ylabel('Well Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSuggestions.to_csv(outputPath, index = False)#Save the data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
